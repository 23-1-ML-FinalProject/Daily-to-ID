{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "collapsed_sections": [
        "oEYG1HsWDnsd"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "7917fb683065420888244c9dbb4ed881": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_393069a1da7947cc892a2eba032ef700",
              "IPY_MODEL_aac634ff451e4c979480edb2b2674fb4",
              "IPY_MODEL_106aa83c7ab5478b89f7b19fbd62e66e"
            ],
            "layout": "IPY_MODEL_20ff58e79f7844b097212ce85ce8bf1c"
          }
        },
        "393069a1da7947cc892a2eba032ef700": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3368905c21724720badfc6fa7370a10d",
            "placeholder": "​",
            "style": "IPY_MODEL_cb7e3f61c4f24391ae34eaf9043e8d4f",
            "value": "Downloading (…)solve/main/README.md: 100%"
          }
        },
        "aac634ff451e4c979480edb2b2674fb4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e603df9324cb4c14bf735e842ab5db56",
            "max": 677,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c13a7573170d4ecea96994a2b4c06844",
            "value": 677
          }
        },
        "106aa83c7ab5478b89f7b19fbd62e66e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_94891d896ef144ada016f81a30c04a55",
            "placeholder": "​",
            "style": "IPY_MODEL_50a083894e164ce181eae6d0655d46fc",
            "value": " 677/677 [00:00&lt;00:00, 25.2kB/s]"
          }
        },
        "20ff58e79f7844b097212ce85ce8bf1c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3368905c21724720badfc6fa7370a10d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cb7e3f61c4f24391ae34eaf9043e8d4f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e603df9324cb4c14bf735e842ab5db56": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c13a7573170d4ecea96994a2b4c06844": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "94891d896ef144ada016f81a30c04a55": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "50a083894e164ce181eae6d0655d46fc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4iznLUG_fpi-",
        "outputId": "0f1bd4d3-7de9-4ef5-e3f6-e978fbeb7c9c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cd /content/drive/MyDrive/23-1-ML/diffusers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7i2QW0GtfwAg",
        "outputId": "c8b1d789-786d-4d70-c604-282d8e27d699"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/23-1-ML/diffusers\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install -e ."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RFjXSYdKfynZ",
        "outputId": "23f1b9af-de47-4f55-df5b-63d205a5d56b"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Obtaining file:///content/drive/MyDrive/23-1-ML/diffusers\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Checking if build backend supports build_editable ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build editable ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing editable metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting importlib-metadata (from diffusers==0.17.0.dev0)\n",
            "  Downloading importlib_metadata-6.6.0-py3-none-any.whl (22 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from diffusers==0.17.0.dev0) (3.12.0)\n",
            "Collecting huggingface-hub>=0.13.2 (from diffusers==0.17.0.dev0)\n",
            "  Downloading huggingface_hub-0.14.1-py3-none-any.whl (224 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m224.5/224.5 kB\u001b[0m \u001b[31m19.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from diffusers==0.17.0.dev0) (1.22.4)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from diffusers==0.17.0.dev0) (2022.10.31)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from diffusers==0.17.0.dev0) (2.27.1)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from diffusers==0.17.0.dev0) (8.4.0)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.13.2->diffusers==0.17.0.dev0) (2023.4.0)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.13.2->diffusers==0.17.0.dev0) (4.65.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.13.2->diffusers==0.17.0.dev0) (6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.13.2->diffusers==0.17.0.dev0) (4.5.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.13.2->diffusers==0.17.0.dev0) (23.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.10/dist-packages (from importlib-metadata->diffusers==0.17.0.dev0) (3.15.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->diffusers==0.17.0.dev0) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->diffusers==0.17.0.dev0) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->diffusers==0.17.0.dev0) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->diffusers==0.17.0.dev0) (3.4)\n",
            "Building wheels for collected packages: diffusers\n",
            "  Building editable for diffusers (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for diffusers: filename=diffusers-0.17.0.dev0-0.editable-py3-none-any.whl size=11125 sha256=07fb7afaba7d0b3d921486b55259b09d33efeb057b019887bc2d361b4b476c31\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-a1mlqtf4/wheels/2d/bb/31/c49b5d6695a561cc019fa97afd5afcc5961d6013937b3e386d\n",
            "Successfully built diffusers\n",
            "Installing collected packages: importlib-metadata, huggingface-hub, diffusers\n",
            "Successfully installed diffusers-0.17.0.dev0 huggingface-hub-0.14.1 importlib-metadata-6.6.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cd /content/drive/MyDrive/23-1-ML/diffusers/examples/dreambooth"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R_IL0xcPgESP",
        "outputId": "8af973c1-276a-4367-e0ed-b50ba67f3cbe"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/23-1-ML/diffusers/examples/dreambooth\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install -r requirements.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kMXCpCx7gIFe",
        "outputId": "4439bc43-f2fa-4b9b-ce4e-6e19fab42ac1"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting accelerate>=0.16.0 (from -r requirements.txt (line 1))\n",
            "  Downloading accelerate-0.19.0-py3-none-any.whl (219 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m219.1/219.1 kB\u001b[0m \u001b[31m15.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 2)) (0.15.2+cu118)\n",
            "Collecting transformers>=4.25.1 (from -r requirements.txt (line 3))\n",
            "  Downloading transformers-4.29.2-py3-none-any.whl (7.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.1/7.1 MB\u001b[0m \u001b[31m49.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting ftfy (from -r requirements.txt (line 4))\n",
            "  Downloading ftfy-6.1.1-py3-none-any.whl (53 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.1/53.1 kB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tensorboard in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 5)) (2.12.2)\n",
            "Requirement already satisfied: Jinja2 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 6)) (3.1.2)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.16.0->-r requirements.txt (line 1)) (1.22.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.16.0->-r requirements.txt (line 1)) (23.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.16.0->-r requirements.txt (line 1)) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.16.0->-r requirements.txt (line 1)) (6.0)\n",
            "Requirement already satisfied: torch>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.16.0->-r requirements.txt (line 1)) (2.0.1+cu118)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torchvision->-r requirements.txt (line 2)) (2.27.1)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision->-r requirements.txt (line 2)) (8.4.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->accelerate>=0.16.0->-r requirements.txt (line 1)) (3.12.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->accelerate>=0.16.0->-r requirements.txt (line 1)) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->accelerate>=0.16.0->-r requirements.txt (line 1)) (1.11.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->accelerate>=0.16.0->-r requirements.txt (line 1)) (3.1)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->accelerate>=0.16.0->-r requirements.txt (line 1)) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.6.0->accelerate>=0.16.0->-r requirements.txt (line 1)) (3.25.2)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.6.0->accelerate>=0.16.0->-r requirements.txt (line 1)) (16.0.5)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.14.1 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.25.1->-r requirements.txt (line 3)) (0.14.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.25.1->-r requirements.txt (line 3)) (2022.10.31)\n",
            "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1 (from transformers>=4.25.1->-r requirements.txt (line 3))\n",
            "  Downloading tokenizers-0.13.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m113.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.25.1->-r requirements.txt (line 3)) (4.65.0)\n",
            "Requirement already satisfied: wcwidth>=0.2.5 in /usr/local/lib/python3.10/dist-packages (from ftfy->-r requirements.txt (line 4)) (0.2.6)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.10/dist-packages (from tensorboard->-r requirements.txt (line 5)) (1.4.0)\n",
            "Requirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.10/dist-packages (from tensorboard->-r requirements.txt (line 5)) (1.54.0)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard->-r requirements.txt (line 5)) (2.17.3)\n",
            "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard->-r requirements.txt (line 5)) (1.0.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard->-r requirements.txt (line 5)) (3.4.3)\n",
            "Requirement already satisfied: protobuf>=3.19.6 in /usr/local/lib/python3.10/dist-packages (from tensorboard->-r requirements.txt (line 5)) (3.20.3)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard->-r requirements.txt (line 5)) (67.7.2)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard->-r requirements.txt (line 5)) (0.7.0)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard->-r requirements.txt (line 5)) (1.8.1)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard->-r requirements.txt (line 5)) (2.3.0)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.10/dist-packages (from tensorboard->-r requirements.txt (line 5)) (0.40.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from Jinja2->-r requirements.txt (line 6)) (2.1.2)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard->-r requirements.txt (line 5)) (5.3.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard->-r requirements.txt (line 5)) (0.3.0)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard->-r requirements.txt (line 5)) (1.16.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard->-r requirements.txt (line 5)) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard->-r requirements.txt (line 5)) (1.3.1)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers>=4.25.1->-r requirements.txt (line 3)) (2023.4.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision->-r requirements.txt (line 2)) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision->-r requirements.txt (line 2)) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision->-r requirements.txt (line 2)) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision->-r requirements.txt (line 2)) (3.4)\n",
            "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard->-r requirements.txt (line 5)) (0.5.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard->-r requirements.txt (line 5)) (3.2.2)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.6.0->accelerate>=0.16.0->-r requirements.txt (line 1)) (1.3.0)\n",
            "Installing collected packages: tokenizers, ftfy, transformers, accelerate\n",
            "Successfully installed accelerate-0.19.0 ftfy-6.1.1 tokenizers-0.13.3 transformers-4.29.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pwd"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "d7yvgkdDmVGr",
        "outputId": "b93c068b-57f5-41e4-ce07-6311c6c44f08"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/drive/MyDrive/23-1-ML/diffusers/examples/dreambooth'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install wandb"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-l11ECxfmxFF",
        "outputId": "594297af-7c1a-4e91-c079-5b899a00482d"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting wandb\n",
            "  Downloading wandb-0.15.3-py3-none-any.whl (2.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m51.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: Click!=8.0.0,>=7.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (8.1.3)\n",
            "Collecting GitPython!=3.1.29,>=1.0.0 (from wandb)\n",
            "  Downloading GitPython-3.1.31-py3-none-any.whl (184 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m184.3/184.3 kB\u001b[0m \u001b[31m23.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (2.27.1)\n",
            "Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (5.9.5)\n",
            "Collecting sentry-sdk>=1.0.0 (from wandb)\n",
            "  Downloading sentry_sdk-1.23.1-py2.py3-none-any.whl (205 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m205.1/205.1 kB\u001b[0m \u001b[31m27.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting docker-pycreds>=0.4.0 (from wandb)\n",
            "  Downloading docker_pycreds-0.4.0-py2.py3-none-any.whl (9.0 kB)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from wandb) (6.0)\n",
            "Collecting pathtools (from wandb)\n",
            "  Downloading pathtools-0.1.2.tar.gz (11 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting setproctitle (from wandb)\n",
            "  Downloading setproctitle-1.3.2-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (30 kB)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from wandb) (67.7.2)\n",
            "Requirement already satisfied: appdirs>=1.4.3 in /usr/local/lib/python3.10/dist-packages (from wandb) (1.4.4)\n",
            "Requirement already satisfied: protobuf!=4.21.0,<5,>=3.19.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (3.20.3)\n",
            "Requirement already satisfied: six>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from docker-pycreds>=0.4.0->wandb) (1.16.0)\n",
            "Collecting gitdb<5,>=4.0.1 (from GitPython!=3.1.29,>=1.0.0->wandb)\n",
            "  Downloading gitdb-4.0.10-py3-none-any.whl (62 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (3.4)\n",
            "Collecting smmap<6,>=3.0.1 (from gitdb<5,>=4.0.1->GitPython!=3.1.29,>=1.0.0->wandb)\n",
            "  Downloading smmap-5.0.0-py3-none-any.whl (24 kB)\n",
            "Building wheels for collected packages: pathtools\n",
            "  Building wheel for pathtools (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pathtools: filename=pathtools-0.1.2-py3-none-any.whl size=8791 sha256=7bf9c74c78d4d0062ca067ca5211438f682f833304e34ea0caa6bf74a479ef22\n",
            "  Stored in directory: /root/.cache/pip/wheels/e7/f3/22/152153d6eb222ee7a56ff8617d80ee5207207a8c00a7aab794\n",
            "Successfully built pathtools\n",
            "Installing collected packages: pathtools, smmap, setproctitle, sentry-sdk, docker-pycreds, gitdb, GitPython, wandb\n",
            "Successfully installed GitPython-3.1.31 docker-pycreds-0.4.0 gitdb-4.0.10 pathtools-0.1.2 sentry-sdk-1.23.1 setproctitle-1.3.2 smmap-5.0.0 wandb-0.15.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from accelerate.utils import write_basic_config\n",
        "write_basic_config()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ozuhjH_EgLuj",
        "outputId": "4a5a286d-bf4c-4498-e473-86fc71fe48bf"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "PosixPath('/root/.cache/huggingface/accelerate/default_config.yaml')"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# TRAIN"
      ],
      "metadata": {
        "id": "ojeFGBE3EvCI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!export MODEL_NAME=\"runwayml/stable-diffusion-v1-5\"\n",
        "!export INSTANCE_DIR=\"/content/drive/MyDrive/23-1-ML/diffusers/examples/dreambooth/Humans\"\n",
        "!export OUTPUT_DIR=\"path-to-save-model\""
      ],
      "metadata": {
        "id": "srXm1nHKgf1f"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!huggingface-cli login"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aWQO9z1fmOc2",
        "outputId": "78ca5ada-cf0c-4df0-ce6e-a00e7c9d8881"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "    _|    _|  _|    _|    _|_|_|    _|_|_|  _|_|_|  _|      _|    _|_|_|      _|_|_|_|    _|_|      _|_|_|  _|_|_|_|\n",
            "    _|    _|  _|    _|  _|        _|          _|    _|_|    _|  _|            _|        _|    _|  _|        _|\n",
            "    _|_|_|_|  _|    _|  _|  _|_|  _|  _|_|    _|    _|  _|  _|  _|  _|_|      _|_|_|    _|_|_|_|  _|        _|_|_|\n",
            "    _|    _|  _|    _|  _|    _|  _|    _|    _|    _|    _|_|  _|    _|      _|        _|    _|  _|        _|\n",
            "    _|    _|    _|_|      _|_|_|    _|_|_|  _|_|_|  _|      _|    _|_|_|      _|        _|    _|    _|_|_|  _|_|_|_|\n",
            "    \n",
            "    To login, `huggingface_hub` requires a token generated from https://huggingface.co/settings/tokens .\n",
            "Token: \n",
            "Add token as git credential? (Y/n) n\n",
            "Token is valid.\n",
            "Your token has been saved to /root/.cache/huggingface/token\n",
            "Login successful\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#   --class_data_dir=\"/content/drive/MyDrive/23-1-ML_Project/dataSet/cropPic\" \\  --class_prompt=\"a photo of a man\"\\"
      ],
      "metadata": {
        "id": "AYIUZMlXGyU3"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!accelerate launch train_dreambooth_lora.py \\\n",
        "  --pretrained_model_name_or_path=\"runwayml/stable-diffusion-v1-5\" \\\n",
        "  --train_text_encoder \\\n",
        "  --instance_data_dir=\"/content/drive/MyDrive/23-1-ML_Project/dataSet/ID_photo\" \\\n",
        "  --output_dir=\"ft-sd15-instance\"\\\n",
        "  --instance_prompt=\"an identification photo of iom man\"\\\n",
        "  --resolution=512 \\\n",
        "  --train_batch_size=1 \\\n",
        "  --gradient_accumulation_steps=1 \\\n",
        "  --checkpointing_steps=25 \\\n",
        "  --learning_rate=1e-4 \\\n",
        "  --report_to=\"wandb\" \\\n",
        "  --lr_scheduler=\"constant\" \\\n",
        "  --lr_warmup_steps=50 \\\n",
        "  --max_train_steps=100 \\\n",
        "  --validation_prompt=\"a high-resolution, identification photo of a iom man with a neutral facial expression and a plain background\"\\\n",
        "  --validation_epochs=25 \\\n",
        "  --seed=\"42\" \\\n",
        "  --push_to_hub"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "57KbRYNqmPPP",
        "outputId": "7d880d45-f75e-4335-b597-72912f64d5ed"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-05-23 05:44:27.254088: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "2023-05-23 05:44:34.848674: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "/usr/local/lib/python3.10/dist-packages/accelerate/accelerator.py:258: FutureWarning: `logging_dir` is deprecated and will be removed in version 0.18.0 of 🤗 Accelerate. Use `project_dir` instead.\n",
            "  warnings.warn(\n",
            "05/23/2023 05:45:15 - INFO - __main__ - Distributed environment: NO\n",
            "Num processes: 1\n",
            "Process index: 0\n",
            "Local process index: 0\n",
            "Device: cuda\n",
            "\n",
            "Mixed precision type: no\n",
            "\n",
            "Downloading (…)okenizer_config.json: 100% 806/806 [00:00<00:00, 5.05MB/s]\n",
            "Downloading (…)tokenizer/vocab.json: 100% 1.06M/1.06M [00:00<00:00, 23.4MB/s]\n",
            "Downloading (…)tokenizer/merges.txt: 100% 525k/525k [00:00<00:00, 172MB/s]\n",
            "Downloading (…)cial_tokens_map.json: 100% 472/472 [00:00<00:00, 4.15MB/s]\n",
            "Downloading (…)_encoder/config.json: 100% 617/617 [00:00<00:00, 4.87MB/s]\n",
            "You are using a model of type clip_text_model to instantiate a model of type . This is not supported for all configurations of models and can yield errors.\n",
            "Downloading (…)cheduler_config.json: 100% 308/308 [00:00<00:00, 2.32MB/s]\n",
            "{'prediction_type', 'dynamic_thresholding_ratio', 'variance_type', 'thresholding', 'sample_max_value', 'clip_sample_range'} was not found in config. Values will be initialized to default values.\n",
            "Downloading pytorch_model.bin: 100% 492M/492M [00:01<00:00, 275MB/s]\n",
            "Downloading (…)main/vae/config.json: 100% 547/547 [00:00<00:00, 4.30MB/s]\n",
            "Downloading (…)on_pytorch_model.bin: 100% 335M/335M [00:01<00:00, 264MB/s]\n",
            "{'scaling_factor'} was not found in config. Values will be initialized to default values.\n",
            "Downloading (…)ain/unet/config.json: 100% 743/743 [00:00<00:00, 5.74MB/s]\n",
            "Downloading (…)on_pytorch_model.bin: 100% 3.44G/3.44G [00:19<00:00, 178MB/s]\n",
            "{'time_embedding_dim', 'addition_embed_type', 'time_cond_proj_dim', 'mid_block_type', 'use_linear_projection', 'resnet_out_scale_factor', 'dual_cross_attention', 'conv_out_kernel', 'class_embeddings_concat', 'class_embed_type', 'only_cross_attention', 'time_embedding_type', 'projection_class_embeddings_input_dim', 'upcast_attention', 'addition_embed_type_num_heads', 'num_class_embeds', 'resnet_skip_time_act', 'cross_attention_norm', 'resnet_time_scale_shift', 'time_embedding_act_fn', 'timestep_post_act', 'encoder_hid_dim', 'mid_block_only_cross_attention', 'conv_in_kernel'} was not found in config. Values will be initialized to default values.\n",
            "Downloading (…)ain/model_index.json: 100% 541/541 [00:00<00:00, 3.03MB/s]\n",
            "Fetching 13 files:   0% 0/13 [00:00<?, ?it/s]\n",
            "Downloading (…)rocessor_config.json: 100% 342/342 [00:00<00:00, 2.07MB/s]\n",
            "Fetching 13 files:   8% 1/13 [00:00<00:01,  6.14it/s]\n",
            "Downloading pytorch_model.bin:   0% 0.00/1.22G [00:00<?, ?B/s]\u001b[A\n",
            "\n",
            "Downloading (…)_checker/config.json: 100% 4.72k/4.72k [00:00<00:00, 18.4MB/s]\n",
            "\n",
            "Downloading pytorch_model.bin:   4% 52.4M/1.22G [00:00<00:02, 472MB/s]\u001b[A\n",
            "Downloading pytorch_model.bin:   9% 105M/1.22G [00:00<00:02, 465MB/s] \u001b[A\n",
            "Downloading pytorch_model.bin:  13% 157M/1.22G [00:00<00:02, 436MB/s]\u001b[A\n",
            "Downloading pytorch_model.bin:  17% 210M/1.22G [00:00<00:02, 446MB/s]\u001b[A\n",
            "Downloading pytorch_model.bin:  22% 262M/1.22G [00:00<00:02, 446MB/s]\u001b[A\n",
            "Downloading pytorch_model.bin:  26% 315M/1.22G [00:00<00:02, 432MB/s]\u001b[A\n",
            "Downloading pytorch_model.bin:  30% 367M/1.22G [00:00<00:02, 424MB/s]\u001b[A\n",
            "Downloading pytorch_model.bin:  34% 419M/1.22G [00:01<00:02, 345MB/s]\u001b[A\n",
            "Downloading pytorch_model.bin:  38% 461M/1.22G [00:01<00:02, 308MB/s]\u001b[A\n",
            "Downloading pytorch_model.bin:  41% 503M/1.22G [00:01<00:02, 287MB/s]\u001b[A\n",
            "Downloading pytorch_model.bin:  44% 535M/1.22G [00:01<00:02, 291MB/s]\u001b[A\n",
            "Downloading pytorch_model.bin:  47% 566M/1.22G [00:01<00:02, 273MB/s]\u001b[A\n",
            "Downloading pytorch_model.bin:  49% 598M/1.22G [00:01<00:02, 262MB/s]\u001b[A\n",
            "Downloading pytorch_model.bin:  52% 629M/1.22G [00:01<00:02, 259MB/s]\u001b[A\n",
            "Downloading pytorch_model.bin:  54% 661M/1.22G [00:02<00:02, 261MB/s]\u001b[A\n",
            "Downloading pytorch_model.bin:  57% 692M/1.22G [00:02<00:02, 259MB/s]\u001b[A\n",
            "Downloading pytorch_model.bin:  59% 724M/1.22G [00:02<00:01, 251MB/s]\u001b[A\n",
            "Downloading pytorch_model.bin:  62% 755M/1.22G [00:02<00:01, 252MB/s]\u001b[A\n",
            "Downloading pytorch_model.bin:  65% 786M/1.22G [00:02<00:01, 256MB/s]\u001b[A\n",
            "Downloading pytorch_model.bin:  67% 818M/1.22G [00:02<00:01, 257MB/s]\u001b[A\n",
            "Downloading pytorch_model.bin:  70% 849M/1.22G [00:02<00:01, 249MB/s]\u001b[A\n",
            "Downloading pytorch_model.bin:  72% 881M/1.22G [00:02<00:01, 239MB/s]\u001b[A\n",
            "Downloading pytorch_model.bin:  75% 912M/1.22G [00:03<00:01, 238MB/s]\u001b[A\n",
            "Downloading pytorch_model.bin:  78% 944M/1.22G [00:03<00:01, 229MB/s]\u001b[A\n",
            "Downloading pytorch_model.bin:  81% 986M/1.22G [00:03<00:00, 273MB/s]\u001b[A\n",
            "Downloading pytorch_model.bin:  84% 1.02G/1.22G [00:03<00:00, 252MB/s]\u001b[A\n",
            "Downloading pytorch_model.bin:  86% 1.05G/1.22G [00:03<00:00, 252MB/s]\u001b[A\n",
            "Downloading pytorch_model.bin:  89% 1.08G/1.22G [00:03<00:00, 248MB/s]\u001b[A\n",
            "Downloading pytorch_model.bin:  91% 1.11G/1.22G [00:03<00:00, 231MB/s]\u001b[A\n",
            "Downloading pytorch_model.bin:  94% 1.14G/1.22G [00:03<00:00, 246MB/s]\u001b[A\n",
            "Downloading pytorch_model.bin:  97% 1.18G/1.22G [00:04<00:00, 269MB/s]\u001b[A\n",
            "Downloading pytorch_model.bin: 100% 1.22G/1.22G [00:04<00:00, 282MB/s]\n",
            "Fetching 13 files: 100% 13/13 [00:04<00:00,  2.89it/s]\n",
            "{'requires_safety_checker'} was not found in config. Values will be initialized to default values.\n",
            "{'prediction_type'} was not found in config. Values will be initialized to default values.\n",
            "{'time_embedding_dim', 'addition_embed_type', 'time_cond_proj_dim', 'mid_block_type', 'use_linear_projection', 'resnet_out_scale_factor', 'dual_cross_attention', 'conv_out_kernel', 'class_embeddings_concat', 'class_embed_type', 'only_cross_attention', 'time_embedding_type', 'projection_class_embeddings_input_dim', 'upcast_attention', 'addition_embed_type_num_heads', 'num_class_embeds', 'resnet_skip_time_act', 'cross_attention_norm', 'resnet_time_scale_shift', 'time_embedding_act_fn', 'timestep_post_act', 'encoder_hid_dim', 'mid_block_only_cross_attention', 'conv_in_kernel'} was not found in config. Values will be initialized to default values.\n",
            "`text_config_dict` is provided which will be used to initialize `CLIPTextConfig`. The value `text_config[\"id2label\"]` will be overriden.\n",
            "{'scaling_factor'} was not found in config. Values will be initialized to default values.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: (1) Create a W&B account\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: (2) Use an existing W&B account\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: (3) Don't visualize my results\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Enter your choice: 2\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: You chose 'Use an existing W&B account'\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.15.3\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/content/drive/MyDrive/23-1-ML/diffusers/examples/dreambooth/wandb/run-20230523_054733-acfhhhpw\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mworldly-bee-25\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/quasar529/dreambooth-lora\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/quasar529/dreambooth-lora/runs/acfhhhpw\u001b[0m\n",
            "05/23/2023 05:47:37 - INFO - __main__ - ***** Running training *****\n",
            "05/23/2023 05:47:37 - INFO - __main__ -   Num examples = 50\n",
            "05/23/2023 05:47:37 - INFO - __main__ -   Num batches each epoch = 50\n",
            "05/23/2023 05:47:37 - INFO - __main__ -   Num Epochs = 2\n",
            "05/23/2023 05:47:37 - INFO - __main__ -   Instantaneous batch size per device = 1\n",
            "05/23/2023 05:47:37 - INFO - __main__ -   Total train batch size (w. parallel, distributed & accumulation) = 1\n",
            "05/23/2023 05:47:37 - INFO - __main__ -   Gradient Accumulation steps = 1\n",
            "05/23/2023 05:47:37 - INFO - __main__ -   Total optimization steps = 100\n",
            "Steps:  25% 25/100 [00:34<01:22,  1.10s/it, loss=0.0699, lr=0.0001]05/23/2023 05:48:11 - INFO - accelerate.accelerator - Saving current state to ft-sd15-instance/checkpoint-25\n",
            "Model weights saved in ft-sd15-instance/checkpoint-25/pytorch_lora_weights.bin\n",
            "05/23/2023 05:48:11 - INFO - accelerate.checkpointing - Optimizer state saved in ft-sd15-instance/checkpoint-25/optimizer.bin\n",
            "05/23/2023 05:48:11 - INFO - accelerate.checkpointing - Scheduler state saved in ft-sd15-instance/checkpoint-25/scheduler.bin\n",
            "05/23/2023 05:48:11 - INFO - accelerate.checkpointing - Random states saved in ft-sd15-instance/checkpoint-25/random_states_0.pkl\n",
            "05/23/2023 05:48:11 - INFO - __main__ - Saved state to ft-sd15-instance/checkpoint-25\n",
            "Steps:  50% 50/100 [01:01<00:50,  1.02s/it, loss=0.00978, lr=0.0001]05/23/2023 05:48:38 - INFO - accelerate.accelerator - Saving current state to ft-sd15-instance/checkpoint-50\n",
            "Model weights saved in ft-sd15-instance/checkpoint-50/pytorch_lora_weights.bin\n",
            "05/23/2023 05:48:38 - INFO - accelerate.checkpointing - Optimizer state saved in ft-sd15-instance/checkpoint-50/optimizer.bin\n",
            "05/23/2023 05:48:38 - INFO - accelerate.checkpointing - Scheduler state saved in ft-sd15-instance/checkpoint-50/scheduler.bin\n",
            "05/23/2023 05:48:38 - INFO - accelerate.checkpointing - Random states saved in ft-sd15-instance/checkpoint-50/random_states_0.pkl\n",
            "05/23/2023 05:48:38 - INFO - __main__ - Saved state to ft-sd15-instance/checkpoint-50\n",
            "Steps:  50% 50/100 [01:01<00:50,  1.02s/it, loss=0.00439, lr=0.0001]05/23/2023 05:48:38 - INFO - __main__ - Running validation... \n",
            " Generating 4 images with prompt: a high-resolution, identification photo of a iom man with a neutral facial expression and a plain background.\n",
            "{'requires_safety_checker'} was not found in config. Values will be initialized to default values.\n",
            "{'prediction_type'} was not found in config. Values will be initialized to default values.\n",
            "`text_config_dict` is provided which will be used to initialize `CLIPTextConfig`. The value `text_config[\"id2label\"]` will be overriden.\n",
            "{'scaling_factor'} was not found in config. Values will be initialized to default values.\n",
            "{'solver_type', 'lambda_min_clipped', 'dynamic_thresholding_ratio', 'lower_order_final', 'variance_type', 'algorithm_type', 'solver_order', 'thresholding', 'sample_max_value', 'use_karras_sigmas'} was not found in config. Values will be initialized to default values.\n",
            "Potential NSFW content was detected in one or more images. A black image will be returned instead. Try again with a different prompt and/or seed.\n",
            "Steps:  75% 75/100 [03:30<00:23,  1.07it/s, loss=0.0984, lr=0.0001]05/23/2023 05:51:07 - INFO - accelerate.accelerator - Saving current state to ft-sd15-instance/checkpoint-75\n",
            "Model weights saved in ft-sd15-instance/checkpoint-75/pytorch_lora_weights.bin\n",
            "05/23/2023 05:51:07 - INFO - accelerate.checkpointing - Optimizer state saved in ft-sd15-instance/checkpoint-75/optimizer.bin\n",
            "05/23/2023 05:51:07 - INFO - accelerate.checkpointing - Scheduler state saved in ft-sd15-instance/checkpoint-75/scheduler.bin\n",
            "05/23/2023 05:51:07 - INFO - accelerate.checkpointing - Random states saved in ft-sd15-instance/checkpoint-75/random_states_0.pkl\n",
            "05/23/2023 05:51:07 - INFO - __main__ - Saved state to ft-sd15-instance/checkpoint-75\n",
            "Steps: 100% 100/100 [03:53<00:00,  1.09it/s, loss=0.19, lr=0.0001]05/23/2023 05:51:30 - INFO - accelerate.accelerator - Saving current state to ft-sd15-instance/checkpoint-100\n",
            "Model weights saved in ft-sd15-instance/checkpoint-100/pytorch_lora_weights.bin\n",
            "05/23/2023 05:51:30 - INFO - accelerate.checkpointing - Optimizer state saved in ft-sd15-instance/checkpoint-100/optimizer.bin\n",
            "05/23/2023 05:51:30 - INFO - accelerate.checkpointing - Scheduler state saved in ft-sd15-instance/checkpoint-100/scheduler.bin\n",
            "05/23/2023 05:51:30 - INFO - accelerate.checkpointing - Random states saved in ft-sd15-instance/checkpoint-100/random_states_0.pkl\n",
            "05/23/2023 05:51:30 - INFO - __main__ - Saved state to ft-sd15-instance/checkpoint-100\n",
            "Steps: 100% 100/100 [03:53<00:00,  1.09it/s, loss=0.0667, lr=0.0001]Model weights saved in ft-sd15-instance/pytorch_lora_weights.bin\n",
            "{'requires_safety_checker'} was not found in config. Values will be initialized to default values.\n",
            "{'prediction_type'} was not found in config. Values will be initialized to default values.\n",
            "{'time_embedding_dim', 'addition_embed_type', 'time_cond_proj_dim', 'mid_block_type', 'use_linear_projection', 'resnet_out_scale_factor', 'dual_cross_attention', 'conv_out_kernel', 'class_embeddings_concat', 'class_embed_type', 'only_cross_attention', 'time_embedding_type', 'projection_class_embeddings_input_dim', 'upcast_attention', 'addition_embed_type_num_heads', 'num_class_embeds', 'resnet_skip_time_act', 'cross_attention_norm', 'resnet_time_scale_shift', 'time_embedding_act_fn', 'timestep_post_act', 'encoder_hid_dim', 'mid_block_only_cross_attention', 'conv_in_kernel'} was not found in config. Values will be initialized to default values.\n",
            "`text_config_dict` is provided which will be used to initialize `CLIPTextConfig`. The value `text_config[\"id2label\"]` will be overriden.\n",
            "{'scaling_factor'} was not found in config. Values will be initialized to default values.\n",
            "{'solver_type', 'lambda_min_clipped', 'dynamic_thresholding_ratio', 'lower_order_final', 'variance_type', 'algorithm_type', 'solver_order', 'thresholding', 'sample_max_value', 'use_karras_sigmas'} was not found in config. Values will be initialized to default values.\n",
            "Loading unet.\n",
            "Loading text_encoder.\n",
            "\n",
            "  0% 0/25 [00:00<?, ?it/s]\u001b[A\n",
            "  4% 1/25 [00:00<00:16,  1.41it/s]\u001b[A\n",
            "  8% 2/25 [00:01<00:13,  1.72it/s]\u001b[A\n",
            " 12% 3/25 [00:01<00:12,  1.81it/s]\u001b[A\n",
            " 16% 4/25 [00:02<00:11,  1.87it/s]\u001b[A\n",
            " 20% 5/25 [00:02<00:10,  1.90it/s]\u001b[A\n",
            " 24% 6/25 [00:03<00:09,  1.93it/s]\u001b[A\n",
            " 28% 7/25 [00:03<00:09,  1.92it/s]\u001b[A\n",
            " 32% 8/25 [00:04<00:08,  1.93it/s]\u001b[A\n",
            " 36% 9/25 [00:04<00:08,  1.93it/s]\u001b[A\n",
            " 40% 10/25 [00:05<00:07,  1.94it/s]\u001b[A\n",
            " 44% 11/25 [00:05<00:07,  1.93it/s]\u001b[A\n",
            " 48% 12/25 [00:06<00:06,  1.93it/s]\u001b[A\n",
            " 52% 13/25 [00:06<00:06,  1.93it/s]\u001b[A\n",
            " 56% 14/25 [00:07<00:05,  1.93it/s]\u001b[A\n",
            " 60% 15/25 [00:07<00:05,  1.93it/s]\u001b[A\n",
            " 64% 16/25 [00:08<00:04,  1.92it/s]\u001b[A\n",
            " 68% 17/25 [00:08<00:04,  1.91it/s]\u001b[A\n",
            " 72% 18/25 [00:09<00:03,  1.91it/s]\u001b[A\n",
            " 76% 19/25 [00:10<00:03,  1.91it/s]\u001b[A\n",
            " 80% 20/25 [00:10<00:02,  1.90it/s]\u001b[A\n",
            " 84% 21/25 [00:11<00:02,  1.90it/s]\u001b[A\n",
            " 88% 22/25 [00:11<00:01,  1.89it/s]\u001b[A\n",
            " 92% 23/25 [00:12<00:01,  1.89it/s]\u001b[A\n",
            " 96% 24/25 [00:12<00:00,  1.89it/s]\u001b[A\n",
            "100% 25/25 [00:13<00:00,  1.90it/s]\n",
            "\n",
            "  0% 0/25 [00:00<?, ?it/s]\u001b[A\n",
            "  4% 1/25 [00:00<00:12,  1.94it/s]\u001b[A\n",
            "  8% 2/25 [00:01<00:12,  1.90it/s]\u001b[A\n",
            " 12% 3/25 [00:01<00:11,  1.90it/s]\u001b[A\n",
            " 16% 4/25 [00:02<00:11,  1.88it/s]\u001b[A\n",
            " 20% 5/25 [00:02<00:10,  1.89it/s]\u001b[A\n",
            " 24% 6/25 [00:03<00:10,  1.87it/s]\u001b[A\n",
            " 28% 7/25 [00:03<00:09,  1.87it/s]\u001b[A\n",
            " 32% 8/25 [00:04<00:09,  1.87it/s]\u001b[A\n",
            " 36% 9/25 [00:04<00:08,  1.87it/s]\u001b[A\n",
            " 40% 10/25 [00:05<00:08,  1.86it/s]\u001b[A\n",
            " 44% 11/25 [00:05<00:07,  1.85it/s]\u001b[A\n",
            " 48% 12/25 [00:06<00:07,  1.84it/s]\u001b[A\n",
            " 52% 13/25 [00:06<00:06,  1.84it/s]\u001b[A\n",
            " 56% 14/25 [00:07<00:05,  1.83it/s]\u001b[A\n",
            " 60% 15/25 [00:08<00:05,  1.83it/s]\u001b[A\n",
            " 64% 16/25 [00:08<00:04,  1.83it/s]\u001b[A\n",
            " 68% 17/25 [00:09<00:04,  1.83it/s]\u001b[A\n",
            " 72% 18/25 [00:09<00:03,  1.83it/s]\u001b[A\n",
            " 76% 19/25 [00:10<00:03,  1.83it/s]\u001b[A\n",
            " 80% 20/25 [00:10<00:02,  1.83it/s]\u001b[A\n",
            " 84% 21/25 [00:11<00:02,  1.83it/s]\u001b[A\n",
            " 88% 22/25 [00:11<00:01,  1.83it/s]\u001b[A\n",
            " 92% 23/25 [00:12<00:01,  1.81it/s]\u001b[A\n",
            " 96% 24/25 [00:13<00:00,  1.82it/s]\u001b[A\n",
            "100% 25/25 [00:13<00:00,  1.84it/s]\n",
            "\n",
            "  0% 0/25 [00:00<?, ?it/s]\u001b[A\n",
            "  4% 1/25 [00:00<00:12,  1.89it/s]\u001b[A\n",
            "  8% 2/25 [00:01<00:12,  1.84it/s]\u001b[A\n",
            " 12% 3/25 [00:01<00:11,  1.84it/s]\u001b[A\n",
            " 16% 4/25 [00:02<00:11,  1.81it/s]\u001b[A\n",
            " 20% 5/25 [00:02<00:11,  1.81it/s]\u001b[A\n",
            " 24% 6/25 [00:03<00:10,  1.79it/s]\u001b[A\n",
            " 28% 7/25 [00:03<00:09,  1.81it/s]\u001b[A\n",
            " 32% 8/25 [00:04<00:09,  1.80it/s]\u001b[A\n",
            " 36% 9/25 [00:04<00:08,  1.80it/s]\u001b[A\n",
            " 40% 10/25 [00:05<00:08,  1.79it/s]\u001b[A\n",
            " 44% 11/25 [00:06<00:07,  1.80it/s]\u001b[A\n",
            " 48% 12/25 [00:06<00:07,  1.80it/s]\u001b[A\n",
            " 52% 13/25 [00:07<00:06,  1.80it/s]\u001b[A\n",
            " 56% 14/25 [00:07<00:06,  1.81it/s]\u001b[A\n",
            " 60% 15/25 [00:08<00:05,  1.81it/s]\u001b[A\n",
            " 64% 16/25 [00:08<00:04,  1.82it/s]\u001b[A\n",
            " 68% 17/25 [00:09<00:04,  1.82it/s]\u001b[A\n",
            " 72% 18/25 [00:09<00:03,  1.83it/s]\u001b[A\n",
            " 76% 19/25 [00:10<00:03,  1.83it/s]\u001b[A\n",
            " 80% 20/25 [00:11<00:02,  1.83it/s]\u001b[A\n",
            " 84% 21/25 [00:11<00:02,  1.83it/s]\u001b[A\n",
            " 88% 22/25 [00:12<00:01,  1.83it/s]\u001b[A\n",
            " 92% 23/25 [00:12<00:01,  1.83it/s]\u001b[A\n",
            " 96% 24/25 [00:13<00:00,  1.83it/s]\u001b[A\n",
            "100% 25/25 [00:13<00:00,  1.82it/s]\n",
            "\n",
            "  0% 0/25 [00:00<?, ?it/s]\u001b[A\n",
            "  4% 1/25 [00:00<00:12,  1.91it/s]\u001b[A\n",
            "  8% 2/25 [00:01<00:12,  1.89it/s]\u001b[A\n",
            " 12% 3/25 [00:01<00:11,  1.89it/s]\u001b[A\n",
            " 16% 4/25 [00:02<00:11,  1.89it/s]\u001b[A\n",
            " 20% 5/25 [00:02<00:10,  1.88it/s]\u001b[A\n",
            " 24% 6/25 [00:03<00:10,  1.88it/s]\u001b[A\n",
            " 28% 7/25 [00:03<00:09,  1.88it/s]\u001b[A\n",
            " 32% 8/25 [00:04<00:09,  1.88it/s]\u001b[A\n",
            " 36% 9/25 [00:04<00:08,  1.87it/s]\u001b[A\n",
            " 40% 10/25 [00:05<00:08,  1.87it/s]\u001b[A\n",
            " 44% 11/25 [00:05<00:07,  1.87it/s]\u001b[A\n",
            " 48% 12/25 [00:06<00:06,  1.87it/s]\u001b[A\n",
            " 52% 13/25 [00:06<00:06,  1.87it/s]\u001b[A\n",
            " 56% 14/25 [00:07<00:05,  1.88it/s]\u001b[A\n",
            " 60% 15/25 [00:07<00:05,  1.88it/s]\u001b[A\n",
            " 64% 16/25 [00:08<00:04,  1.88it/s]\u001b[A\n",
            " 68% 17/25 [00:09<00:04,  1.88it/s]\u001b[A\n",
            " 72% 18/25 [00:09<00:03,  1.89it/s]\u001b[A\n",
            " 76% 19/25 [00:10<00:03,  1.89it/s]\u001b[A\n",
            " 80% 20/25 [00:10<00:02,  1.90it/s]\u001b[A\n",
            " 84% 21/25 [00:11<00:02,  1.89it/s]\u001b[A\n",
            " 88% 22/25 [00:11<00:01,  1.90it/s]\u001b[A\n",
            " 92% 23/25 [00:12<00:01,  1.90it/s]\u001b[A\n",
            " 96% 24/25 [00:12<00:00,  1.90it/s]\u001b[A\n",
            "100% 25/25 [00:13<00:00,  1.89it/s]\n",
            "\n",
            "Upload 17 LFS files:   0% 0/17 [00:00<?, ?it/s]\u001b[A\n",
            "\n",
            "optimizer.bin:   0% 0.00/6.64M [00:00<?, ?B/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "pytorch_lora_weights.bin:   0% 0.00/8.16M [00:00<?, ?B/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "scheduler.bin:   0% 0.00/563 [00:00<?, ?B/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "random_states_0.pkl:   0% 0.00/14.7k [00:00<?, ?B/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "optimizer.bin:   0% 0.00/6.64M [00:00<?, ?B/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "optimizer.bin:  95% 6.32M/6.64M [00:00<00:00, 55.4MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "random_states_0.pkl: 100% 14.7k/14.7k [00:00<00:00, 132kB/s]\n",
            "scheduler.bin: 100% 563/563 [00:00<00:00, 4.50kB/s]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "optimizer.bin:  81% 5.36M/6.64M [00:00<00:00, 42.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "pytorch_lora_weights.bin:  16% 1.33M/8.16M [00:00<00:01, 6.64MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_lora_weights.bin:   0% 0.00/8.16M [00:00<?, ?B/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "optimizer.bin: 100% 6.64M/6.64M [00:00<00:00, 24.1MB/s]\n",
            "random_states_0.pkl: 100% 14.7k/14.7k [00:00<00:00, 280kB/s]\n",
            "\n",
            "\n",
            "\n",
            "pytorch_lora_weights.bin:  48% 3.87M/8.16M [00:00<00:00, 14.5MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "optimizer.bin: 100% 6.64M/6.64M [00:00<00:00, 20.7MB/s]\n",
            "\n",
            "Upload 17 LFS files:   6% 1/17 [00:00<00:06,  2.58it/s]\u001b[A\n",
            "\n",
            "scheduler.bin:   0% 0.00/563 [00:00<?, ?B/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "scheduler.bin: 100% 563/563 [00:00<00:00, 16.5kB/s]\n",
            "\n",
            "\n",
            "\n",
            "pytorch_lora_weights.bin:  87% 7.12M/8.16M [00:00<00:00, 21.2MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "pytorch_lora_weights.bin:   0% 0.00/8.16M [00:00<?, ?B/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "random_states_0.pkl: 100% 14.7k/14.7k [00:00<00:00, 260kB/s]\n",
            "pytorch_lora_weights.bin: 100% 8.16M/8.16M [00:00<00:00, 25.3MB/s]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "scheduler.bin: 100% 563/563 [00:00<00:00, 20.2kB/s]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "optimizer.bin: 100% 6.64M/6.64M [00:00<00:00, 27.9MB/s]\n",
            "pytorch_lora_weights.bin: 100% 8.16M/8.16M [00:00<00:00, 37.2MB/s]\n",
            "\n",
            "\n",
            "pytorch_lora_weights.bin:   0% 0.00/8.16M [00:00<?, ?B/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "random_states_0.pkl:   0% 0.00/14.7k [00:00<?, ?B/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_lora_weights.bin: 100% 8.16M/8.16M [00:00<00:00, 11.0MB/s]\n",
            "scheduler.bin: 100% 563/563 [00:00<00:00, 15.6kB/s]\n",
            "random_states_0.pkl: 100% 14.7k/14.7k [00:00<00:00, 189kB/s]\n",
            "\n",
            "\n",
            "\n",
            "pytorch_lora_weights.bin:   0% 0.00/8.16M [00:00<?, ?B/s]\u001b[A\u001b[A\u001b[A\n",
            "optimizer.bin: 100% 6.64M/6.64M [00:00<00:00, 35.1MB/s]\n",
            "pytorch_lora_weights.bin: 100% 8.16M/8.16M [00:00<00:00, 40.2MB/s]\n",
            "\n",
            "pytorch_lora_weights.bin: 100% 8.16M/8.16M [00:00<00:00, 42.2MB/s]\n",
            "Upload 17 LFS files: 100% 17/17 [00:01<00:00, 16.81it/s]\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish... \u001b[32m(success).\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: loss ▇▅▃▂▃▃▂▂▁▁▃▄▂▁▄▁▂▁▃▁▁▃▂▂▁▁▃▃▂▂▄▁▂▂▂▃█▃▃▂\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:   lr ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: loss 0.0667\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:   lr 0.0001\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run \u001b[33mworldly-bee-25\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/quasar529/dreambooth-lora/runs/acfhhhpw\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 8 media file(s), 2 artifact file(s) and 0 other file(s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20230523_054733-acfhhhpw/logs\u001b[0m\n",
            "/usr/local/lib/python3.10/dist-packages/wandb/sdk/wandb_run.py:2088: UserWarning: Run (acfhhhpw) is finished. The call to `_console_raw_callback` will be ignored. Please make sure that you are using an active run.\n",
            "  lambda data: self._console_raw_callback(\"stderr\", data),\n",
            "Steps: 100% 100/100 [05:26<00:00,  3.26s/it, loss=0.0667, lr=0.0001]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install accelerate\n",
        "!pip install git+https://github.com/huggingface/diffusers\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dzTWb0Xmw5rV",
        "outputId": "f5fd979a-70ee-4db4-8c25-1573dfe32857"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: accelerate in /usr/local/lib/python3.10/dist-packages (0.19.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from accelerate) (1.22.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (23.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from accelerate) (6.0)\n",
            "Requirement already satisfied: torch>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (2.0.1+cu118)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->accelerate) (3.12.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->accelerate) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->accelerate) (1.11.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->accelerate) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->accelerate) (3.1.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->accelerate) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.6.0->accelerate) (3.25.2)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.6.0->accelerate) (16.0.5)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.6.0->accelerate) (2.1.2)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.6.0->accelerate) (1.3.0)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting git+https://github.com/huggingface/diffusers\n",
            "  Cloning https://github.com/huggingface/diffusers to /tmp/pip-req-build-i90_l1d2\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/huggingface/diffusers /tmp/pip-req-build-i90_l1d2\n",
            "  Resolved https://github.com/huggingface/diffusers to commit 2f997f30ab660472561f5e1b5232d4f116315b1b\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.10/dist-packages (from diffusers==0.17.0.dev0) (6.6.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from diffusers==0.17.0.dev0) (3.12.0)\n",
            "Requirement already satisfied: huggingface-hub>=0.13.2 in /usr/local/lib/python3.10/dist-packages (from diffusers==0.17.0.dev0) (0.14.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from diffusers==0.17.0.dev0) (1.22.4)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from diffusers==0.17.0.dev0) (2022.10.31)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from diffusers==0.17.0.dev0) (2.27.1)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from diffusers==0.17.0.dev0) (8.4.0)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.13.2->diffusers==0.17.0.dev0) (2023.4.0)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.13.2->diffusers==0.17.0.dev0) (4.65.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.13.2->diffusers==0.17.0.dev0) (6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.13.2->diffusers==0.17.0.dev0) (4.5.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.13.2->diffusers==0.17.0.dev0) (23.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.10/dist-packages (from importlib-metadata->diffusers==0.17.0.dev0) (3.15.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->diffusers==0.17.0.dev0) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->diffusers==0.17.0.dev0) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->diffusers==0.17.0.dev0) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->diffusers==0.17.0.dev0) (3.4)\n",
            "Building wheels for collected packages: diffusers\n",
            "  Building wheel for diffusers (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for diffusers: filename=diffusers-0.17.0.dev0-py3-none-any.whl size=1010748 sha256=c20af38ccc58632ff89684954b26c1e7a208fb515773606db21f866fc761e484\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-5j9eu785/wheels/f7/7d/99/d361489e5762e3464b3811bc629e94cf5bf5ef44dd5c3c4d52\n",
            "Successfully built diffusers\n",
            "Installing collected packages: diffusers\n",
            "  Attempting uninstall: diffusers\n",
            "    Found existing installation: diffusers 0.17.0.dev0\n",
            "    Uninstalling diffusers-0.17.0.dev0:\n",
            "      Successfully uninstalled diffusers-0.17.0.dev0\n",
            "Successfully installed diffusers-0.17.0.dev0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from huggingface_hub.repocard import RepoCard\n",
        "from diffusers import StableDiffusionPipeline\n",
        "import torch \n",
        "\n",
        "lora_model_id = \"MayIBorn/ft-sd15-class-instance2\"\n",
        "card = RepoCard.load(lora_model_id)\n",
        "base_model_id = card.data.to_dict()[\"base_model\"]\n",
        "\n",
        "pipe = StableDiffusionPipeline.from_pretrained(base_model_id, torch_dtype=torch.float16)\n",
        "pipe = pipe.to(\"cuda\")\n",
        "pipe.load_lora_weights(lora_model_id)\n",
        "\n",
        "prompt = \"a high-resolution, identification photo of an iom person with a neutral facial expression and a plain background. The subject must be placed center and facing forward with a natural head position, and the image should be well-lit, revealing the man's face and facial features clearly. no accessories\"\n",
        "negative_prompt=\"((duplicate, out of frame, worst quality, low quality, normal quality:1.4)), (blur effect), 2 heads, (black and white photo), cropped image, deformed hands, twisted fingers, long neck, malformed hands, missing limb, disfigured, blurry, poorly drawn face, mutation, distorted face, draft, grainy, watermark.\"\n",
        "image = pipe(prompt=prompt,negative_prompt=negative_prompt,num_inference_steps=200).images[0]  \n",
        "image\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "7917fb683065420888244c9dbb4ed881",
            "393069a1da7947cc892a2eba032ef700",
            "aac634ff451e4c979480edb2b2674fb4",
            "106aa83c7ab5478b89f7b19fbd62e66e",
            "20ff58e79f7844b097212ce85ce8bf1c",
            "3368905c21724720badfc6fa7370a10d",
            "cb7e3f61c4f24391ae34eaf9043e8d4f",
            "e603df9324cb4c14bf735e842ab5db56",
            "c13a7573170d4ecea96994a2b4c06844",
            "94891d896ef144ada016f81a30c04a55",
            "50a083894e164ce181eae6d0655d46fc"
          ]
        },
        "id": "uO-Fhc70xdKM",
        "outputId": "9959cfc2-959b-4d5f-83f3-29c28e461ec0"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)solve/main/README.md:   0%|          | 0.00/677 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "7917fb683065420888244c9dbb4ed881"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "`text_config_dict` is provided which will be used to initialize `CLIPTextConfig`. The value `text_config[\"id2label\"]` will be overriden.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[31m╭─\u001b[0m\u001b[31m──────────────────────────────\u001b[0m\u001b[31m \u001b[0m\u001b[1;31mTraceback \u001b[0m\u001b[1;2;31m(most recent call last)\u001b[0m\u001b[31m \u001b[0m\u001b[31m───────────────────────────────\u001b[0m\u001b[31m─╮\u001b[0m\n",
              "\u001b[31m│\u001b[0m in \u001b[92m<cell line: 10>\u001b[0m:\u001b[94m10\u001b[0m                                                                            \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m \u001b[2;33m/usr/local/lib/python3.10/dist-packages/diffusers/pipelines/\u001b[0m\u001b[1;33mpipeline_utils.py\u001b[0m:\u001b[94m675\u001b[0m in \u001b[92mto\u001b[0m          \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m 672 \u001b[0m\u001b[2m│   │   │   │   │   \u001b[0m\u001b[33mf\u001b[0m\u001b[33m\"\u001b[0m\u001b[33mThe module \u001b[0m\u001b[33m'\u001b[0m\u001b[33m{\u001b[0mmodule.\u001b[91m__class__\u001b[0m.\u001b[91m__name__\u001b[0m\u001b[33m}\u001b[0m\u001b[33m'\u001b[0m\u001b[33m has been loaded in 8bit a\u001b[0m  \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m 673 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m)                                                                         \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m 674 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[94melse\u001b[0m:                                                                         \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m 675 \u001b[2m│   │   │   │   \u001b[0mmodule.to(torch_device, torch_dtype)                                      \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m 676 \u001b[0m\u001b[2m│   │   │   \u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m 677 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[94mif\u001b[0m (                                                                          \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m 678 \u001b[0m\u001b[2m│   │   │   │   \u001b[0mmodule.dtype == torch.float16                                             \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m \u001b[2;33m/usr/local/lib/python3.10/dist-packages/transformers/\u001b[0m\u001b[1;33mmodeling_utils.py\u001b[0m:\u001b[94m1878\u001b[0m in \u001b[92mto\u001b[0m                \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m1875 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[33m\"\u001b[0m\u001b[33m model has already been set to the correct devices and casted to the co\u001b[0m  \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m1876 \u001b[0m\u001b[2m│   │   │   \u001b[0m)                                                                             \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m1877 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94melse\u001b[0m:                                                                             \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m1878 \u001b[2m│   │   │   \u001b[0m\u001b[94mreturn\u001b[0m \u001b[96msuper\u001b[0m().to(*args, **kwargs)                                            \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m1879 \u001b[0m\u001b[2m│   \u001b[0m                                                                                      \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m1880 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mdef\u001b[0m \u001b[92mhalf\u001b[0m(\u001b[96mself\u001b[0m, *args):                                                                \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m1881 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[2m# Checks if the model has been loaded in 8-bit\u001b[0m                                    \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m \u001b[2;33m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/\u001b[0m\u001b[1;33mmodule.py\u001b[0m:\u001b[94m1145\u001b[0m in \u001b[92mto\u001b[0m                    \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m1142 \u001b[0m\u001b[2m│   │   │   │   │   │   │   \u001b[0mnon_blocking, memory_format=convert_to_format)                \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m1143 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[94mreturn\u001b[0m t.to(device, dtype \u001b[94mif\u001b[0m t.is_floating_point() \u001b[95mor\u001b[0m t.is_complex() \u001b[94melse\u001b[0m \u001b[94mNo\u001b[0m  \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m1144 \u001b[0m\u001b[2m│   │   \u001b[0m                                                                                  \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m1145 \u001b[2m│   │   \u001b[0m\u001b[94mreturn\u001b[0m \u001b[96mself\u001b[0m._apply(convert)                                                       \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m1146 \u001b[0m\u001b[2m│   \u001b[0m                                                                                      \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m1147 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mdef\u001b[0m \u001b[92mregister_full_backward_pre_hook\u001b[0m(                                                  \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m1148 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[96mself\u001b[0m,                                                                             \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m \u001b[2;33m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/\u001b[0m\u001b[1;33mmodule.py\u001b[0m:\u001b[94m797\u001b[0m in \u001b[92m_apply\u001b[0m                 \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m 794 \u001b[0m\u001b[2m│   \u001b[0m                                                                                      \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m 795 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mdef\u001b[0m \u001b[92m_apply\u001b[0m(\u001b[96mself\u001b[0m, fn):                                                                 \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m 796 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mfor\u001b[0m module \u001b[95min\u001b[0m \u001b[96mself\u001b[0m.children():                                                    \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m 797 \u001b[2m│   │   │   \u001b[0mmodule._apply(fn)                                                             \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m 798 \u001b[0m\u001b[2m│   │   \u001b[0m                                                                                  \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m 799 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mdef\u001b[0m \u001b[92mcompute_should_use_set_data\u001b[0m(tensor, tensor_applied):                          \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m 800 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[94mif\u001b[0m torch._has_compatible_shallow_copy_type(tensor, tensor_applied):           \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m \u001b[2;33m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/\u001b[0m\u001b[1;33mmodule.py\u001b[0m:\u001b[94m797\u001b[0m in \u001b[92m_apply\u001b[0m                 \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m 794 \u001b[0m\u001b[2m│   \u001b[0m                                                                                      \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m 795 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mdef\u001b[0m \u001b[92m_apply\u001b[0m(\u001b[96mself\u001b[0m, fn):                                                                 \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m 796 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mfor\u001b[0m module \u001b[95min\u001b[0m \u001b[96mself\u001b[0m.children():                                                    \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m 797 \u001b[2m│   │   │   \u001b[0mmodule._apply(fn)                                                             \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m 798 \u001b[0m\u001b[2m│   │   \u001b[0m                                                                                  \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m 799 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mdef\u001b[0m \u001b[92mcompute_should_use_set_data\u001b[0m(tensor, tensor_applied):                          \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m 800 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[94mif\u001b[0m torch._has_compatible_shallow_copy_type(tensor, tensor_applied):           \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m \u001b[2;33m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/\u001b[0m\u001b[1;33mmodule.py\u001b[0m:\u001b[94m797\u001b[0m in \u001b[92m_apply\u001b[0m                 \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m 794 \u001b[0m\u001b[2m│   \u001b[0m                                                                                      \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m 795 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mdef\u001b[0m \u001b[92m_apply\u001b[0m(\u001b[96mself\u001b[0m, fn):                                                                 \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m 796 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mfor\u001b[0m module \u001b[95min\u001b[0m \u001b[96mself\u001b[0m.children():                                                    \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m 797 \u001b[2m│   │   │   \u001b[0mmodule._apply(fn)                                                             \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m 798 \u001b[0m\u001b[2m│   │   \u001b[0m                                                                                  \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m 799 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mdef\u001b[0m \u001b[92mcompute_should_use_set_data\u001b[0m(tensor, tensor_applied):                          \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m 800 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[94mif\u001b[0m torch._has_compatible_shallow_copy_type(tensor, tensor_applied):           \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m \u001b[2;33m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/\u001b[0m\u001b[1;33mmodule.py\u001b[0m:\u001b[94m797\u001b[0m in \u001b[92m_apply\u001b[0m                 \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m 794 \u001b[0m\u001b[2m│   \u001b[0m                                                                                      \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m 795 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mdef\u001b[0m \u001b[92m_apply\u001b[0m(\u001b[96mself\u001b[0m, fn):                                                                 \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m 796 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mfor\u001b[0m module \u001b[95min\u001b[0m \u001b[96mself\u001b[0m.children():                                                    \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m 797 \u001b[2m│   │   │   \u001b[0mmodule._apply(fn)                                                             \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m 798 \u001b[0m\u001b[2m│   │   \u001b[0m                                                                                  \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m 799 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mdef\u001b[0m \u001b[92mcompute_should_use_set_data\u001b[0m(tensor, tensor_applied):                          \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m 800 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[94mif\u001b[0m torch._has_compatible_shallow_copy_type(tensor, tensor_applied):           \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m \u001b[2;33m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/\u001b[0m\u001b[1;33mmodule.py\u001b[0m:\u001b[94m820\u001b[0m in \u001b[92m_apply\u001b[0m                 \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m 817 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[2m# track autograd history of `param_applied`, so we have to use\u001b[0m                \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m 818 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[2m# `with torch.no_grad():`\u001b[0m                                                     \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m 819 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[94mwith\u001b[0m torch.no_grad():                                                         \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m 820 \u001b[2m│   │   │   │   \u001b[0mparam_applied = fn(param)                                                 \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m 821 \u001b[0m\u001b[2m│   │   │   \u001b[0mshould_use_set_data = compute_should_use_set_data(param, param_applied)       \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m 822 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[94mif\u001b[0m should_use_set_data:                                                       \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m 823 \u001b[0m\u001b[2m│   │   │   │   \u001b[0mparam.data = param_applied                                                \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m \u001b[2;33m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/\u001b[0m\u001b[1;33mmodule.py\u001b[0m:\u001b[94m1143\u001b[0m in \u001b[92mconvert\u001b[0m               \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m1140 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[94mif\u001b[0m convert_to_format \u001b[95mis\u001b[0m \u001b[95mnot\u001b[0m \u001b[94mNone\u001b[0m \u001b[95mand\u001b[0m t.dim() \u001b[95min\u001b[0m (\u001b[94m4\u001b[0m, \u001b[94m5\u001b[0m):                       \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m1141 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[94mreturn\u001b[0m t.to(device, dtype \u001b[94mif\u001b[0m t.is_floating_point() \u001b[95mor\u001b[0m t.is_complex() \u001b[94mels\u001b[0m  \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m1142 \u001b[0m\u001b[2m│   │   │   │   │   │   │   \u001b[0mnon_blocking, memory_format=convert_to_format)                \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m1143 \u001b[2m│   │   │   \u001b[0m\u001b[94mreturn\u001b[0m t.to(device, dtype \u001b[94mif\u001b[0m t.is_floating_point() \u001b[95mor\u001b[0m t.is_complex() \u001b[94melse\u001b[0m \u001b[94mNo\u001b[0m  \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m1144 \u001b[0m\u001b[2m│   │   \u001b[0m                                                                                  \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m1145 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mreturn\u001b[0m \u001b[96mself\u001b[0m._apply(convert)                                                       \u001b[31m│\u001b[0m\n",
              "\u001b[31m│\u001b[0m   \u001b[2m1146 \u001b[0m                                                                                          \u001b[31m│\u001b[0m\n",
              "\u001b[31m╰──────────────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n",
              "\u001b[1;91mKeyboardInterrupt\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800000; text-decoration-color: #800000\">╭─────────────────────────────── </span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">Traceback </span><span style=\"color: #bf7f7f; text-decoration-color: #bf7f7f; font-weight: bold\">(most recent call last)</span><span style=\"color: #800000; text-decoration-color: #800000\"> ────────────────────────────────╮</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">&lt;cell line: 10&gt;</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">10</span>                                                                            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/usr/local/lib/python3.10/dist-packages/diffusers/pipelines/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">pipeline_utils.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">675</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">to</span>          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 672 │   │   │   │   │   </span><span style=\"color: #808000; text-decoration-color: #808000\">f\"The module '{</span>module.<span style=\"color: #ff0000; text-decoration-color: #ff0000\">__class__</span>.<span style=\"color: #ff0000; text-decoration-color: #ff0000\">__name__</span><span style=\"color: #808000; text-decoration-color: #808000\">}' has been loaded in 8bit a</span>  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 673 │   │   │   │   </span>)                                                                         <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 674 │   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">else</span>:                                                                         <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span> 675 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   </span>module.to(torch_device, torch_dtype)                                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 676 │   │   │   </span>                                                                              <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 677 │   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> (                                                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 678 │   │   │   │   </span>module.dtype == torch.float16                                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/usr/local/lib/python3.10/dist-packages/transformers/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">modeling_utils.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">1878</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">to</span>                <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1875 │   │   │   │   </span><span style=\"color: #808000; text-decoration-color: #808000\">\" model has already been set to the correct devices and casted to the co</span>  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1876 │   │   │   </span>)                                                                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1877 │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">else</span>:                                                                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>1878 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">super</span>().to(*args, **kwargs)                                            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1879 │   </span>                                                                                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1880 │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">def</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">half</span>(<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>, *args):                                                                <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1881 │   │   # Checks if the model has been loaded in 8-bit</span>                                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/usr/local/lib/python3.10/dist-packages/torch/nn/modules/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">module.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">1145</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">to</span>                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1142 │   │   │   │   │   │   │   </span>non_blocking, memory_format=convert_to_format)                <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1143 │   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> t.to(device, dtype <span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> t.is_floating_point() <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> t.is_complex() <span style=\"color: #0000ff; text-decoration-color: #0000ff\">else</span> <span style=\"color: #0000ff; text-decoration-color: #0000ff\">No</span>  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1144 │   │   </span>                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>1145 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._apply(convert)                                                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1146 │   </span>                                                                                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1147 │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">def</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">register_full_backward_pre_hook</span>(                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1148 │   │   </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>,                                                                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/usr/local/lib/python3.10/dist-packages/torch/nn/modules/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">module.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">797</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">_apply</span>                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 794 │   </span>                                                                                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 795 │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">def</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">_apply</span>(<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>, fn):                                                                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 796 │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">for</span> module <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">in</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.children():                                                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span> 797 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span>module._apply(fn)                                                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 798 │   │   </span>                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 799 │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">def</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">compute_should_use_set_data</span>(tensor, tensor_applied):                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 800 │   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> torch._has_compatible_shallow_copy_type(tensor, tensor_applied):           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/usr/local/lib/python3.10/dist-packages/torch/nn/modules/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">module.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">797</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">_apply</span>                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 794 │   </span>                                                                                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 795 │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">def</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">_apply</span>(<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>, fn):                                                                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 796 │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">for</span> module <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">in</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.children():                                                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span> 797 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span>module._apply(fn)                                                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 798 │   │   </span>                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 799 │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">def</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">compute_should_use_set_data</span>(tensor, tensor_applied):                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 800 │   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> torch._has_compatible_shallow_copy_type(tensor, tensor_applied):           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/usr/local/lib/python3.10/dist-packages/torch/nn/modules/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">module.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">797</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">_apply</span>                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 794 │   </span>                                                                                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 795 │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">def</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">_apply</span>(<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>, fn):                                                                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 796 │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">for</span> module <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">in</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.children():                                                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span> 797 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span>module._apply(fn)                                                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 798 │   │   </span>                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 799 │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">def</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">compute_should_use_set_data</span>(tensor, tensor_applied):                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 800 │   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> torch._has_compatible_shallow_copy_type(tensor, tensor_applied):           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/usr/local/lib/python3.10/dist-packages/torch/nn/modules/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">module.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">797</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">_apply</span>                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 794 │   </span>                                                                                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 795 │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">def</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">_apply</span>(<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>, fn):                                                                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 796 │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">for</span> module <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">in</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.children():                                                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span> 797 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span>module._apply(fn)                                                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 798 │   │   </span>                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 799 │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">def</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">compute_should_use_set_data</span>(tensor, tensor_applied):                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 800 │   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> torch._has_compatible_shallow_copy_type(tensor, tensor_applied):           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/usr/local/lib/python3.10/dist-packages/torch/nn/modules/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">module.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">820</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">_apply</span>                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 817 │   │   │   # track autograd history of `param_applied`, so we have to use</span>                <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 818 │   │   │   # `with torch.no_grad():`</span>                                                     <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 819 │   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">with</span> torch.no_grad():                                                         <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span> 820 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   </span>param_applied = fn(param)                                                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 821 │   │   │   </span>should_use_set_data = compute_should_use_set_data(param, param_applied)       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 822 │   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> should_use_set_data:                                                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 823 │   │   │   │   </span>param.data = param_applied                                                <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/usr/local/lib/python3.10/dist-packages/torch/nn/modules/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">module.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">1143</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">convert</span>               <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1140 │   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> convert_to_format <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">is</span> <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">not</span> <span style=\"color: #0000ff; text-decoration-color: #0000ff\">None</span> <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">and</span> t.dim() <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">in</span> (<span style=\"color: #0000ff; text-decoration-color: #0000ff\">4</span>, <span style=\"color: #0000ff; text-decoration-color: #0000ff\">5</span>):                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1141 │   │   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> t.to(device, dtype <span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> t.is_floating_point() <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> t.is_complex() <span style=\"color: #0000ff; text-decoration-color: #0000ff\">els</span>  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1142 │   │   │   │   │   │   │   </span>non_blocking, memory_format=convert_to_format)                <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>1143 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> t.to(device, dtype <span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> t.is_floating_point() <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> t.is_complex() <span style=\"color: #0000ff; text-decoration-color: #0000ff\">else</span> <span style=\"color: #0000ff; text-decoration-color: #0000ff\">No</span>  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1144 │   │   </span>                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1145 │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._apply(convert)                                                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1146 </span>                                                                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
              "<span style=\"color: #800000; text-decoration-color: #800000\">╰──────────────────────────────────────────────────────────────────────────────────────────────────╯</span>\n",
              "<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold\">KeyboardInterrupt</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = \"a high-resolution, identification photo of an man with a neutral facial expression and a plain background. The subject must be placed center and facing forward with a natural head position, and the image should be well-lit, revealing the man's face and facial features clearly. no accessories\"\n",
        "negative_prompt=\"((duplicate, out of frame, worst quality, low quality, normal quality:1.4)), (blur effect), 2 heads, black and white photo, cropped image, deformed hands, twisted fingers, long neck, malformed hands, missing limb, disfigured, blurry, poorly drawn face, mutation, distorted face, draft, grainy, watermark.\"\n",
        "image = pipe(prompt=prompt,negative_prompt=negative_prompt,num_inference_steps=25).images[0]  \n",
        "image"
      ],
      "metadata": {
        "id": "U20w_Eny8aQh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image = pipe(prompt=\"super-realistic, best-quality, A photo of a person, upper body, looking at the viewer, blank background\",\n",
        "             negative_prompt=\"Cropped image, out of frame, disfigured, blurry, poorly drawn face, mutation, distorted face, draft, grainy, ugly, poorly drawn, distorted proportions, many people.\" ,\n",
        "             num_inference_steps=100).images[0]\n",
        "image"
      ],
      "metadata": {
        "id": "0kOiAGTMyK00"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "normal_pipe = StableDiffusionPipeline.from_pretrained(\"stabilityai/stable-diffusion-2\", torch_dtype=torch.float16)\n",
        "normal_pipe = pipe.to(\"cuda\")"
      ],
      "metadata": {
        "id": "E_ydDIr96YJO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image = normal_pipe(prompt=\"Complex detailed painting of a fantasy medieval cleric woman walking through a field of flowers by rembrandt, cleric wearing a tiara and a ornate embroidered hooded cloak, bright blue eyes, evocative, sharp focus, close shot, long blonde hair, high contrast, low saturation, lush flower field and clouds background, backlighting..\",\n",
        "             negative_prompt=\"(nsfw:1.5), ((worst quality, low quality, normal quality:1.4)), (blur effect), (mature, comic, cartoon:0.5), lowers low resolution, rnbad anatomy, low quality anatomy, bad hands, bad nails, bad legs, bad fingers, (bad toes, tiptoes), extra digit, extra hands, extra fingers, rnextra arms, extra legs, fewer digit, lowers low quality face, lowers low quality eyes, cropped hands, cropped legs, cropped arms, rncropped fingers, fused fingers, too many fingers, tattoo, missing fingers, ugly, text, (muscular:0.4), collage, more than one person in focus, rnbad anatomy, (more than two arm per body:1.5), (more than two leg per body:1.4), ((more than five fingers on one hand:1.4)), rnmulti arms, multi legs, bad arm anatomy, bad leg anatomy, bad hand anatomy, bad finger anatomy, bad detailed background, rnunclear architectural outline, non-linear background, elf-ears, hair crosses the screen border, obesity, fat, (blurry), mutated hands and fingers, rndisfigured, fused, hat, bad ankle, (((one man:1.7)))\" ,\n",
        "             num_inference_steps=100).images[0]\n",
        "image\n",
        "#((Best quality)), ((masterpiece)), ((realistic)) a human ID photo. The style will emphasize realism, using photography as the medium. The photo is focusing on the subject's facial features. The final result will be a high definition, detailed photo of the human face"
      ],
      "metadata": {
        "id": "H4K5v4du7H-a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Test Prompt Without Training"
      ],
      "metadata": {
        "id": "lFMY3wu6DAYv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from diffusers import StableDiffusionPipeline, EulerDiscreteScheduler\n",
        "import torch\n",
        "\n",
        "model_id = \"stabilityai/stable-diffusion-2-base\"\n",
        "\n",
        "# Use the Euler scheduler here instead\n",
        "scheduler = EulerDiscreteScheduler.from_pretrained(model_id, subfolder=\"scheduler\")\n",
        "pipe = StableDiffusionPipeline.from_pretrained(model_id, scheduler=scheduler, torch_dtype=torch.float16)\n",
        "pipe = pipe.to(\"cuda\")\n",
        "\n",
        "prompt = \"a photo of an astronaut riding a horse on mars\"\n",
        "image = pipe(prompt).images[0]  \n",
        "    \n",
        "image.save(\"astronaut_rides_horse.png\")\n",
        "image"
      ],
      "metadata": {
        "id": "wu9-z2Z5_5Av"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_id = \"runwayml/stable-diffusion-v1-5\"\n",
        "pipe = StableDiffusionPipeline.from_pretrained(model_id, torch_dtype=torch.float16)\n",
        "pipe = pipe.to(\"cuda\")"
      ],
      "metadata": {
        "id": "U8IpW_TSC-sM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = \"a high-resolution, identification photo of an asian man with a neutral facial expression and a plain background. The subject must be placed center and facing forward with a natural head position, and the image should be well-lit, revealing the man's face and facial features clearly. no accessories\"\n",
        "negative_prompt=\"((duplicate, out of frame, worst quality, low quality, normal quality:1.4)), (blur effect), 2 heads, black and white photo, cropped image, deformed hands, twisted fingers, long neck, malformed hands, missing limb, disfigured, blurry, poorly drawn face, mutation, distorted face, draft, grainy, watermark.\"\n",
        "image = pipe(prompt=prompt,negative_prompt=negative_prompt).images[0]  \n",
        "image"
      ],
      "metadata": {
        "id": "BgCGBMDoBMEG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image\n",
        "from diffusers import StableDiffusionImg2ImgPipeline\n",
        "\n",
        "pipe = StableDiffusionImg2ImgPipeline.from_pretrained(base_model_id, torch_dtype=torch.float16)\n",
        "pipe = pipe.to(\"cuda\")\n",
        "pipe.load_lora_weights(lora_model_id)\n",
        "init_image = Image.open(\"/content/drive/MyDrive/23-1-ML_Project/pexels-andrea-piacquadio-845434.jpg\").convert(\"RGB\")\n",
        "init_image = init_image.resize((768, 512))\n",
        "\n",
        "prompt = \"Generate a realistic photo of a person. The person should be facing forward and be the main focus of the image. The background should be blurred or out of focus to draw attention to the person. The image should be high resolution and have natural-looking lighting and shadows. The person's features should be recognizable and the image should convey a sense of emotion or personality\"\n",
        "images = pipe(prompt=prompt, image=init_image, strength=0.75, guidance_scale=7.5).images\n",
        "images[0].save(f\"{prompt}.png\")"
      ],
      "metadata": {
        "id": "tHLBl1jNyLhe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = \"Generate a realistic photo of a person. The person should be facing forward and be the main focus of the image. The background should be blurred or out of focus to draw attention to the person. The image should be high resolution and have natural-looking lighting and shadows. The person's features should be recognizable and the image should convey a sense of emotion or personality\"\n",
        "images = pipe(prompt=prompt, image=init_image, strength=0.75, guidance_scale=7.5).images\n",
        "images[0].save(\"long.png\")"
      ],
      "metadata": {
        "id": "bZPmzQ_lJki1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "import torch\n",
        "from PIL import Image\n",
        "from io import BytesIO\n",
        "\n",
        "from diffusers import StableDiffusionImg2ImgPipeline\n",
        "\n",
        "device = \"cuda\"\n",
        "model_id_or_path = \"runwayml/stable-diffusion-v1-5\"\n",
        "i2i_pipe = StableDiffusionImg2ImgPipeline.from_pretrained(model_id_or_path, torch_dtype=torch.float16)\n",
        "i2i_pipe = i2i_pipe.to(device)\n",
        "\n",
        "init_image = Image.open(\"/content/drive/MyDrive/23-1-ML/portrait_of_person/ludovic-migneault-4uj3iZ5m084-unsplash.jpg\").convert(\"RGB\")\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "deNm7CE3GIs8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = \"a high-resolution, identification photo of an man with a neutral facial expression and a plain background. The subject must be placed center and facing forward with a natural head position, and the image should be well-lit, revealing the man's face and facial features clearly. no accessories\"\n",
        "negative_prompt=\"((duplicate, out of frame, worst quality, low quality, normal quality:1.4)), (blur effect), 2 heads, black and white photo, cropped image, deformed hands, twisted fingers, long neck, malformed hands, missing limb, disfigured, blurry, poorly drawn face, mutation, distorted face, draft, grainy, watermark.\"\n",
        "\n",
        "images = i2i_pipe(prompt=prompt, image=init_image, strength=0.75, guidance_scale=7.5).images\n",
        "images[0].save(\"fantasy_landscape.png\")\n",
        "images"
      ],
      "metadata": {
        "id": "bReA5FmiHeHi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# image selecting"
      ],
      "metadata": {
        "id": "oEYG1HsWDnsd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pathlib import Path\n",
        "Path(\"/content/drive/MyDrive/23-1-ML/diffusers/examples/dreambooth/Humans\")"
      ],
      "metadata": {
        "id": "TVsNrkHmTr2U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(list(Path(\"/content/drive/MyDrive/23-1-ML/diffusers/examples/dreambooth/Humans\").iterdir()))"
      ],
      "metadata": {
        "id": "SHNCohjU_pXG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "instance_data_root=\"/content/drive/MyDrive/23-1-ML/diffusers/examples/dreambooth/Humans\"\n",
        "num_instance_images = len(list(Path(\"/content/drive/MyDrive/23-1-ML/diffusers/examples/dreambooth/Humans\").iterdir()))\n",
        "instance_images_path = list(Path(instance_data_root).iterdir())\n"
      ],
      "metadata": {
        "id": "8rqM801nAGFi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image\n",
        "Image.open(instance_images_path[7000% num_instance_images])"
      ],
      "metadata": {
        "id": "Lf59vgGJ_7HU"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}